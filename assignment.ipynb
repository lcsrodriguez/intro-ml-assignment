{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fecc5932",
   "metadata": {},
   "source": [
    "# Introduction to ML - Assignment 1 - April 9, 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7dff60",
   "metadata": {},
   "source": [
    "## General principles for a correct model development: Read carefully!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3db3732",
   "metadata": {},
   "source": [
    "**The pre-modeling phase aims to obtain a clean training and test database to feed the learning algorithms.**\n",
    "\n",
    "It is a very (the most?) important phase of the model development process as the Garbage In-Garbage Out principle applies ... so take your time to get it right.\n",
    "\n",
    "Once the raw data has been acquired (how to do that depends on the support and the characteristics of the raw data (structured or unstructured data)) in a suitable environment (pandas) the first thing is to do an **Exploratory Data Analysis - EDA**, in simple words ... **look the data**:\n",
    "- make graphs (histograms, scatter plots, box-plots ...)\n",
    "- analyze the marginal distributions (mean, variance, max, min, percentiles)\n",
    "- analyze the joint distribution of the variables (correlations)\n",
    "\n",
    "Once you have an idea of what your data is like, you can start addressing any (but almost certain) problems you will encounter ...\n",
    "\n",
    "The most common answer these questions (not necessarily in this order ...):\n",
    "\n",
    "- **are there any non-numeric formats (strings) in the data?**\n",
    "    - almost all ML algorithms can work only with numeric data (int or float) and therefore this data must be converted into numeric data.\n",
    "    - in general this process goes under the name of **'category encoding'** and the type of encoding to use depends on the characteristics of the variables ...\n",
    "\n",
    "\n",
    "- **are there missing data for some variables**? \n",
    "    - and if so what is the best strategy to manage them?\n",
    "        - delete the variables?\n",
    "        - delete observations with missing data?\n",
    "        - replace the missing data with an estimate of the missing value?\n",
    "\n",
    "\n",
    "  Which strategy to adopt depends on the number of observations and variables you have available...\n",
    "\n",
    "- **are there outliers in the variables**?\n",
    "    - how do i identify them?\n",
    "        - univariate or multivariate analysis...\n",
    "    - how do I manage them?\n",
    "        - delete observations with anomalous data?\n",
    "        - replace the outliers with an estimate?\n",
    "    - are outliers really a problem?\n",
    "        - there are algorithms that are robust in the presence of outliers\n",
    "\n",
    "\n",
    "  Again which strategy to adopt depends on the size of the sample you have available ...\n",
    "\n",
    "**Two points to remember**:\n",
    "\n",
    "- the principle less data = more variance always applies ...\n",
    "- **if you use estimates to replace missing or outliers values** these estimates must be computed\n",
    "    - **after** you have splitted the sample into training-test subsamples\n",
    "    - **on training data only** and then applied to test data\n",
    "\n",
    "**How to organize these activities?**\n",
    "\n",
    "- try to avoid spaghetti code\n",
    "- try to write functions that group the operations that are related to the same transformation\n",
    "- try to use Pipelines to organize the flow of data between these functions\n",
    "\n",
    "\n",
    "**The paragraphs reported in each exercise are indicative only and serve to remind the student of the minimal set of analyzes that must be carried out. The student is free to add any other type of analysis he deems appropriate at his discretion**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e85aa2",
   "metadata": {},
   "source": [
    "## Exercise 1 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52802c22",
   "metadata": {},
   "source": [
    "In this exercise, you need to process a data file that contains many invalid lines. You will find some null data and others field with various values (eg 'Missing' or NA) which indicate that the corresponding data is not valid. Furthermore, even in some numeric columns there may be characters (eg '-') which indicate the absence of a data. Also in this case you have to understand how to deal with the data (eg replace with 0). When you have found a clean sub-set of data you will need to convert all the columns into numerical data by applying the techniques learned in the course to deal with categorical data. Finally, choose a data normalization method.\n",
    "\n",
    "**For this exercise you need to use the file: exercise-1-1.csv**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea71135",
   "metadata": {},
   "source": [
    "### Import Libraries and Upload Data File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "dc120710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference-date</th>\n",
       "      <th>status</th>\n",
       "      <th>status-prev</th>\n",
       "      <th>status-after</th>\n",
       "      <th>counterparty-type</th>\n",
       "      <th>economic-sector-code</th>\n",
       "      <th>geographic-area</th>\n",
       "      <th>balance</th>\n",
       "      <th>limit-balance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>corporate-type-2</td>\n",
       "      <td>4228</td>\n",
       "      <td>mid-west</td>\n",
       "      <td>117.16</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>retail-type-2</td>\n",
       "      <td>5928</td>\n",
       "      <td>east-coast</td>\n",
       "      <td>39.49</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>retail-type-2</td>\n",
       "      <td>5928</td>\n",
       "      <td>mid-west</td>\n",
       "      <td>14.10</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small-enterprise</td>\n",
       "      <td>6078</td>\n",
       "      <td>south</td>\n",
       "      <td>80.581.10</td>\n",
       "      <td>80.506.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>retail-type-2</td>\n",
       "      <td>5928</td>\n",
       "      <td>south</td>\n",
       "      <td>17.01</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reference-date  status  status-prev  status-after counterparty-type  \\\n",
       "id                                                                       \n",
       "1      2019-01-01       1            0             0  corporate-type-2   \n",
       "2      2019-01-01       1            0             0     retail-type-2   \n",
       "3      2019-01-01       1            0             0     retail-type-2   \n",
       "4      2019-01-01       1            0             0  small-enterprise   \n",
       "5      2019-01-01       1            0             0     retail-type-2   \n",
       "\n",
       "   economic-sector-code geographic-area      balance limit-balance  \n",
       "id                                                                  \n",
       "1                  4228        mid-west       117.16          -     \n",
       "2                  5928      east-coast        39.49          -     \n",
       "3                  5928        mid-west        14.10          -     \n",
       "4                  6078           south   80.581.10     80.506.12   \n",
       "5                  5928           south        17.01          -     "
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import of useful libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Gathering the main file called : exercise-1-1.csv\n",
    "df = pd.read_csv(\"exercise-1-1.csv\", sep=\";\", index_col=\"id\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "hollow-recruitment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 15139 entries, 1 to 15139\n",
      "Data columns (total 9 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   reference-date        15139 non-null  object\n",
      " 1   status                15139 non-null  int64 \n",
      " 2   status-prev           15139 non-null  int64 \n",
      " 3   status-after          15139 non-null  int64 \n",
      " 4   counterparty-type     1933 non-null   object\n",
      " 5   economic-sector-code  15139 non-null  object\n",
      " 6   geographic-area       15139 non-null  object\n",
      " 7   balance               15139 non-null  object\n",
      " 8   limit-balance         15139 non-null  object\n",
      "dtypes: int64(3), object(6)\n",
      "memory usage: 1.2+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(15139, 9)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get some informations about the different columns composing the csv file\n",
    "df.info()\n",
    "\n",
    "# Get the general shape of the DataFrame\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convinced-switzerland",
   "metadata": {},
   "source": [
    "We have an initial Pandas DataFrame composed of 9 columns (plus 1 column for the unique id of each row) and 15139 rows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35780a8b",
   "metadata": {},
   "source": [
    "### Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personalized-peripheral",
   "metadata": {},
   "source": [
    "We can handle duplicate rows by using the following instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "medium-wright",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13889, 9)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates(inplace=True) # we keep the \"keep\" argument to its default value : \"first\"\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "textile-chocolate",
   "metadata": {},
   "source": [
    "We have removed more than 1000 lines which were duplicated in the original DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serious-supplement",
   "metadata": {},
   "source": [
    "**Extra Remark** : We don't modify the columns labels because these are in lowercase and with dash, so everything is understandable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aadf3e1",
   "metadata": {},
   "source": [
    "**Check for Uniqueness of Data** - Avoid to use columns with a single constant value for all records ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "25f6709a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first determine for each column, the number of different values in this column by using the following Pandas method\n",
    "#df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "federal-dependence",
   "metadata": {},
   "source": [
    "We see that the column labeled as `status-prev` and `status-after` only contain 1 single value for each tuple in the DataFrame.\n",
    "\n",
    "$\\Longrightarrow$ They are <ins style='color:red'>**Zero-variance predictors**</ins> which refer to input features that contain a single value across the entire set of observations. \n",
    "\n",
    "\n",
    "$\\Longrightarrow$ Accordingly, they do not add any value to the prediction algorithm since the target variable is not affected by the input value, making them redundant.\n",
    "\n",
    "$\\Longrightarrow$ Thanks to Pandas, we will remove these two columns by using the following method :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "systematic-robertson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference-date</th>\n",
       "      <th>status</th>\n",
       "      <th>counterparty-type</th>\n",
       "      <th>economic-sector-code</th>\n",
       "      <th>geographic-area</th>\n",
       "      <th>balance</th>\n",
       "      <th>limit-balance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>corporate-type-2</td>\n",
       "      <td>4228</td>\n",
       "      <td>mid-west</td>\n",
       "      <td>117.16</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>retail-type-2</td>\n",
       "      <td>5928</td>\n",
       "      <td>east-coast</td>\n",
       "      <td>39.49</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>retail-type-2</td>\n",
       "      <td>5928</td>\n",
       "      <td>mid-west</td>\n",
       "      <td>14.10</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>small-enterprise</td>\n",
       "      <td>6078</td>\n",
       "      <td>south</td>\n",
       "      <td>80.581.10</td>\n",
       "      <td>80.506.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>retail-type-2</td>\n",
       "      <td>5928</td>\n",
       "      <td>south</td>\n",
       "      <td>17.01</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reference-date  status counterparty-type economic-sector-code  \\\n",
       "id                                                                 \n",
       "1      2019-01-01       1  corporate-type-2                 4228   \n",
       "2      2019-01-01       1     retail-type-2                 5928   \n",
       "3      2019-01-01       1     retail-type-2                 5928   \n",
       "4      2019-01-01       1  small-enterprise                 6078   \n",
       "5      2019-01-01       1     retail-type-2                 5928   \n",
       "\n",
       "   geographic-area      balance limit-balance  \n",
       "id                                             \n",
       "1         mid-west       117.16          -     \n",
       "2       east-coast        39.49          -     \n",
       "3         mid-west        14.10          -     \n",
       "4            south   80.581.10     80.506.12   \n",
       "5            south        17.01          -     "
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns = df.columns[df.nunique() == 1], inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "executive-saint",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13889, 7)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "internal-marsh",
   "metadata": {},
   "source": [
    "We now have only 7 columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7463cab3",
   "metadata": {},
   "source": [
    "**Cleaning Data** - Converting date to datetime, replace '-' with appropriate value in the 'limit-balance' column, you should also pay attention to the number format of 'balance' and 'limit-balance' column, it does not seem the original format can be used as a numerical format ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "580a40a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 13889 entries, 1 to 15139\n",
      "Data columns (total 7 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   reference-date        13889 non-null  object\n",
      " 1   status                13889 non-null  int64 \n",
      " 2   counterparty-type     1903 non-null   object\n",
      " 3   economic-sector-code  13889 non-null  object\n",
      " 4   geographic-area       13889 non-null  object\n",
      " 5   balance               13889 non-null  object\n",
      " 6   limit-balance         13889 non-null  object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 868.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "union-sharp",
   "metadata": {},
   "source": [
    "We see that :\n",
    "- The columns `balance` and `limit-balance` have an `object` type. We have to convert it into 2 `float64` fields by first handling carefuly the way they are originally set (with a point and not a comma).\n",
    "- The column `reference-date` is an object column. However, Pandas offers the opportunity to deal with `datetime64`-typed column.\n",
    "- The column `economic-sector-code` is an integer-populated column $\\Longrightarrow$ we have to convert the column into a `int64` column.\n",
    "\n",
    "**References** :\n",
    "- https://pandas.pydata.org/docs/user_guide/basics.html#basics-dtypes\n",
    "- https://pbpython.com/pandas_dtypes.html\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "partial-diploma",
   "metadata": {},
   "source": [
    "$\\longrightarrow$ **Column `reference-date`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "valuable-intermediate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dealing with reference-date : convert the column from date to datetime\n",
    "df[\"reference-date\"] =  pd.to_datetime(df[\"reference-date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closing-tongue",
   "metadata": {},
   "source": [
    "$\\longrightarrow$ **Column `limit-balance`** (only the dash issue)\n",
    "\n",
    "We have to replace the \"-\" by NaN values. However, we see that we cannot just perform a `replace(\"-\", \"<sth>\")` because we have some spaces surrounding the \"-\". The right solution here is to perform a regex-driven replace operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "regulation-beach",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"balance\"].replace(to_replace=\"\\s*-\\s*\", value=np.NaN, inplace=True, regex=True)\n",
    "df[\"limit-balance\"].replace(to_replace=\"\\s*-\\s*\", value=np.NaN, inplace=True, regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baking-figure",
   "metadata": {},
   "source": [
    "$\\longrightarrow$ **Columns `balance` and `limit-balance`**\n",
    "\n",
    "We have pointed out the format of `balance` and `limit-balance` data aren't really compatible with a direct `float64` conversion. \n",
    "\n",
    "Indeed, we see several times that :\n",
    "- We can have a correct float (set as a string) with 1 point\n",
    "- But we can also find some tuples with 2 points. My hypothesis is the first point (at the left) represents a separator for the $10^3$ gap\n",
    "\n",
    "\n",
    "<b style='color:red'>Solution</b> : We have to introduce and implement a function which will perform replacement and conversion : if we find 2 points, we remove the first one and concatenate the 2 parts of the results; otherwise, we do nothing.\n",
    "\n",
    "<b style='color:green'>Remark</b> : We can use a $\\lambda$-function to exploit the conciseness of Python.\n",
    "\n",
    "\n",
    "At final step, we can perform the cast of the whole column as a `float64` type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "nearby-modem",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dealing with the point/comma issue in balance and limit-balance columns\n",
    "# We have to cast the balance column to a float64 type\n",
    "\n",
    "\n",
    "#df[\"balance\"].astype(\"float64\")\n",
    "\n",
    "# Removing useless spaces\n",
    "df[\"balance\"].replace(\" \", \"\")\n",
    "\n",
    "def filter_numbers(x):\n",
    "    \"\"\"\n",
    "    Function filtering and cleaning properly the balance and limit-balance columns\n",
    "    :param x: String representing a float\n",
    "    \"\"\"\n",
    "    if not pd.isna(x):\n",
    "        if x.count(\".\") == 2:\n",
    "            x_tmp = x.split(\".\")\n",
    "            return x_tmp[0] + x_tmp[1] + \".\" + x_tmp[2]\n",
    "        return x\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "df[\"balance\"] = df[\"balance\"].apply(filter_numbers)\n",
    "df[\"limit-balance\"] = df[\"limit-balance\"].apply(filter_numbers)\n",
    "\n",
    "df[\"balance\"] = pd.to_numeric(df[\"balance\"], errors=\"coerce\")\n",
    "df[\"limit-balance\"] = pd.to_numeric(df[\"limit-balance\"], errors=\"coerce\")\n",
    "\n",
    "# We have an issue concerning the double point into the balance/limit-balance columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "fourth-catch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 13889 entries, 1 to 15139\n",
      "Data columns (total 7 columns):\n",
      " #   Column                Non-Null Count  Dtype         \n",
      "---  ------                --------------  -----         \n",
      " 0   reference-date        13889 non-null  datetime64[ns]\n",
      " 1   status                13889 non-null  int64         \n",
      " 2   counterparty-type     1903 non-null   object        \n",
      " 3   economic-sector-code  13843 non-null  float64       \n",
      " 4   geographic-area       13889 non-null  object        \n",
      " 5   balance               13843 non-null  float64       \n",
      " 6   limit-balance         1948 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(3), int64(1), object(2)\n",
      "memory usage: 868.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference-date</th>\n",
       "      <th>status</th>\n",
       "      <th>counterparty-type</th>\n",
       "      <th>economic-sector-code</th>\n",
       "      <th>geographic-area</th>\n",
       "      <th>balance</th>\n",
       "      <th>limit-balance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>corporate-type-2</td>\n",
       "      <td>117.16</td>\n",
       "      <td>mid-west</td>\n",
       "      <td>117.16</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>retail-type-2</td>\n",
       "      <td>39.49</td>\n",
       "      <td>east-coast</td>\n",
       "      <td>39.49</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>retail-type-2</td>\n",
       "      <td>14.10</td>\n",
       "      <td>mid-west</td>\n",
       "      <td>14.10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>small-enterprise</td>\n",
       "      <td>80581.10</td>\n",
       "      <td>south</td>\n",
       "      <td>80581.10</td>\n",
       "      <td>80506.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>retail-type-2</td>\n",
       "      <td>17.01</td>\n",
       "      <td>south</td>\n",
       "      <td>17.01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reference-date  status counterparty-type  economic-sector-code  \\\n",
       "id                                                                  \n",
       "1      2019-01-01       1  corporate-type-2                117.16   \n",
       "2      2019-01-01       1     retail-type-2                 39.49   \n",
       "3      2019-01-01       1     retail-type-2                 14.10   \n",
       "4      2019-01-01       1  small-enterprise              80581.10   \n",
       "5      2019-01-01       1     retail-type-2                 17.01   \n",
       "\n",
       "   geographic-area   balance  limit-balance  \n",
       "id                                           \n",
       "1         mid-west    117.16            NaN  \n",
       "2       east-coast     39.49            NaN  \n",
       "3         mid-west     14.10            NaN  \n",
       "4            south  80581.10       80506.12  \n",
       "5            south     17.01            NaN  "
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af9b20e",
   "metadata": {},
   "source": [
    "### Categorical Data Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "billion-mistress",
   "metadata": {},
   "source": [
    "We have 2 features variables which are set as \"categorical\" : `counterparty-type` and `geographic-area`.\n",
    "\n",
    "We can see that these 2 variables only take few values :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "endangered-hazard",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "counterparty-type    9\n",
       "geographic-area      7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()[[\"counterparty-type\", \"geographic-area\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "local-saver",
   "metadata": {},
   "source": [
    "We have to adopt a clear strategy to handle these categorical data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d52d8e9",
   "metadata": {},
   "source": [
    "### Remove High-Correlated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "7e9358f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reference-date            12\n",
       "status                     4\n",
       "counterparty-type          9\n",
       "economic-sector-code    9567\n",
       "geographic-area            7\n",
       "balance                 9567\n",
       "limit-balance           1155\n",
       "dtype: int64"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# insert your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516bec87",
   "metadata": {},
   "source": [
    "## Exercise 2 - Classification with Support Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eca464b",
   "metadata": {},
   "source": [
    "In this exercise you will have to use the data reported in the file **exercise-1-2.csv** which contains a series of data related to diagnostic images. The data relate to a number of characteristics found during breast cancer analyzes. You must use the SVM method to correctly classify the data. Remember to divide the data into a training set and a test set, then measure the effectiveness of your method. Finally, produce the confusion matrix related to your analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ae6938",
   "metadata": {},
   "source": [
    "### Loading data and import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7725521e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912eb048",
   "metadata": {},
   "source": [
    "### Visual Analysis of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fbc30f",
   "metadata": {},
   "source": [
    "In this case you have a very large number of features and clearly you cannot make an n-dimension plotter! Try to select pairs of variables that can be informative..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f275c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf3a0f7",
   "metadata": {},
   "source": [
    "### Create Training and Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c81e752f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fd5e75",
   "metadata": {},
   "source": [
    "### Apply SVM Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "942dc2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e82256",
   "metadata": {},
   "source": [
    "### Analyze Accuracy and Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ba4cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your code here..."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
